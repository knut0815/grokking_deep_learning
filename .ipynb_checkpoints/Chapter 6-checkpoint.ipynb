{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - loss: [0.04], prediction: -0.19999999999999996\n",
      "epoch: 1 - loss: [0.0256], prediction: -0.15999999999999992\n",
      "epoch: 2 - loss: [0.016384], prediction: -0.1279999999999999\n",
      "epoch: 3 - loss: [0.01048576], prediction: -0.10239999999999982\n",
      "epoch: 4 - loss: [0.00671089], prediction: -0.08191999999999977\n",
      "epoch: 5 - loss: [0.00429497], prediction: -0.06553599999999982\n",
      "epoch: 6 - loss: [0.00274878], prediction: -0.05242879999999994\n",
      "epoch: 7 - loss: [0.00175922], prediction: -0.04194304000000004\n",
      "epoch: 8 - loss: [0.0011259], prediction: -0.03355443200000008\n",
      "epoch: 9 - loss: [0.00072058], prediction: -0.02684354560000002\n",
      "epoch: 10 - loss: [0.00046117], prediction: -0.021474836479999926\n",
      "epoch: 11 - loss: [0.00029515], prediction: -0.01717986918399994\n",
      "epoch: 12 - loss: [0.00018889], prediction: -0.013743895347199997\n",
      "epoch: 13 - loss: [0.00012089], prediction: -0.010995116277759953\n",
      "epoch: 14 - loss: [7.73712525e-05], prediction: -0.008796093022207963\n",
      "epoch: 15 - loss: [4.95176016e-05], prediction: -0.007036874417766459\n",
      "epoch: 16 - loss: [3.1691265e-05], prediction: -0.0056294995342132115\n",
      "epoch: 17 - loss: [2.02824096e-05], prediction: -0.004503599627370569\n",
      "epoch: 18 - loss: [1.29807421e-05], prediction: -0.003602879701896544\n",
      "epoch: 19 - loss: [8.30767497e-06], prediction: -0.002882303761517324\n",
      "epoch: 20 - loss: [5.31691198e-06], prediction: -0.0023058430092137705\n",
      "epoch: 21 - loss: [3.40282367e-06], prediction: -0.0018446744073710164\n",
      "epoch: 22 - loss: [2.17780715e-06], prediction: -0.0014757395258968575\n",
      "epoch: 23 - loss: [1.39379657e-06], prediction: -0.001180591620717486\n",
      "epoch: 24 - loss: [8.92029808e-07], prediction: -0.0009444732965739888\n",
      "epoch: 25 - loss: [5.70899077e-07], prediction: -0.0007555786372592799\n",
      "epoch: 26 - loss: [3.65375409e-07], prediction: -0.0006044629098074239\n",
      "epoch: 27 - loss: [2.33840262e-07], prediction: -0.0004835703278458503\n",
      "epoch: 28 - loss: [1.49657768e-07], prediction: -0.00038685626227663583\n",
      "epoch: 29 - loss: [9.57809713e-08], prediction: -0.00030948500982130867\n",
      "epoch: 30 - loss: [6.12998216e-08], prediction: -0.0002475880078569581\n",
      "epoch: 31 - loss: [3.92318858e-08], prediction: -0.0001980704062856109\n",
      "epoch: 32 - loss: [2.51084069e-08], prediction: -0.00015845632502853313\n",
      "epoch: 33 - loss: [1.60693804e-08], prediction: -0.00012676506002273769\n",
      "epoch: 34 - loss: [1.02844035e-08], prediction: -0.00010141204801827897\n",
      "epoch: 35 - loss: [6.58201823e-09], prediction: -8.112963841466758e-05\n",
      "epoch: 36 - loss: [4.21249167e-09], prediction: -6.490371073164525e-05\n",
      "epoch: 37 - loss: [2.69599467e-09], prediction: -5.192296858536061e-05\n",
      "epoch: 38 - loss: [1.72543659e-09], prediction: -4.153837486819967e-05\n",
      "epoch: 39 - loss: [1.10427942e-09], prediction: -3.3230699894470916e-05\n",
      "epoch: 40 - loss: [7.06738826e-10], prediction: -2.658455991566555e-05\n",
      "epoch: 41 - loss: [4.52312849e-10], prediction: -2.126764793253244e-05\n",
      "epoch: 42 - loss: [2.89480223e-10], prediction: -1.7014118345981544e-05\n",
      "epoch: 43 - loss: [1.85267343e-10], prediction: -1.3611294676696417e-05\n",
      "epoch: 44 - loss: [1.18571099e-10], prediction: -1.0889035741312725e-05\n",
      "epoch: 45 - loss: [7.58855036e-11], prediction: -8.711228593138998e-06\n",
      "epoch: 46 - loss: [4.85667223e-11], prediction: -6.968982874555607e-06\n",
      "epoch: 47 - loss: [3.10827023e-11], prediction: -5.5751862997333035e-06\n",
      "epoch: 48 - loss: [1.98929295e-11], prediction: -4.460149039875461e-06\n",
      "epoch: 49 - loss: [1.27314749e-11], prediction: -3.5681192318559596e-06\n"
     ]
    }
   ],
   "source": [
    "# Streetlight configuration\n",
    "xs = np.array([[1, 0, 1],\n",
    "               [0, 1, 1],\n",
    "               [0, 0, 1],\n",
    "               [1, 1, 1],\n",
    "               [0, 1, 1],\n",
    "               [1, 0, 1]])\n",
    "\n",
    "# Walk versus stop\n",
    "ys = np.array([[0],\n",
    "               [1],\n",
    "               [0],\n",
    "               [1],\n",
    "               [1],\n",
    "               [0]])\n",
    "\n",
    "# Grab one data entry\n",
    "x_i = xs[0]\n",
    "y_i = ys[0]\n",
    "\n",
    "epochs = 50\n",
    "lr = 0.1\n",
    "\n",
    "# Neural network weights (one layer)\n",
    "w = np.array([0.5, 0.48, -0.7])\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_hat = x_i.dot(w)\n",
    "    l = (y_hat - y_i) ** 2.0\n",
    "    \n",
    "    dl_dw = (y_hat - y_i) * x_i\n",
    "    \n",
    "    w -= lr * dl_dw\n",
    "    \n",
    "    print('epoch: {} - loss: {}, prediction: {}'.format(i, l, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    actual: [0], prediction: -0.19999999999999996\n",
      "    actual: [1], prediction: -0.19999999999999996\n",
      "    actual: [0], prediction: -0.5599999999999999\n",
      "    actual: [1], prediction: 0.616\n",
      "    actual: [1], prediction: 0.17279999999999995\n",
      "    actual: [0], prediction: 0.17552\n",
      "epoch: 0 - total loss: [2.65612311]\n",
      "    actual: [0], prediction: 0.14041599999999999\n",
      "    actual: [1], prediction: 0.3066464\n",
      "    actual: [0], prediction: -0.34513824\n",
      "    actual: [1], prediction: 1.006637344\n",
      "    actual: [1], prediction: 0.4785034751999999\n",
      "    actual: [0], prediction: 0.26700416768\n",
      "epoch: 1 - total loss: [0.96287018]\n",
      "    actual: [0], prediction: 0.213603334144\n",
      "    actual: [1], prediction: 0.5347420299776\n",
      "    actual: [0], prediction: -0.26067345110016\n",
      "    actual: [1], prediction: 1.131942884509696\n",
      "    actual: [1], prediction: 0.6274723921901568\n",
      "    actual: [0], prediction: 0.25433999330650114\n",
      "epoch: 2 - total loss: [0.55091659]\n",
      "    actual: [0], prediction: 0.20347199464520094\n",
      "    actual: [1], prediction: 0.6561967149569552\n",
      "    actual: [0], prediction: -0.22194850395099494\n",
      "    actual: [1], prediction: 1.166258650532124\n",
      "    actual: [1], prediction: 0.7139004922542389\n",
      "    actual: [0], prediction: 0.2147109952837161\n",
      "epoch: 3 - total loss: [0.36445837]\n",
      "    actual: [0], prediction: 0.17176879622697286\n",
      "    actual: [1], prediction: 0.7324724146523223\n",
      "    actual: [0], prediction: -0.19966478845083285\n",
      "    actual: [1], prediction: 1.16977699453412\n",
      "    actual: [1], prediction: 0.771989011660117\n",
      "    actual: [0], prediction: 0.17297997428859369\n",
      "epoch: 4 - total loss: [0.25167687]\n",
      "    actual: [0], prediction: 0.13838397943087496\n",
      "    actual: [1], prediction: 0.7864548139561468\n",
      "    actual: [0], prediction: -0.1836567869927348\n",
      "    actual: [1], prediction: 1.163248019006011\n",
      "    actual: [1], prediction: 0.8148799260629888\n",
      "    actual: [0], prediction: 0.1362897844408577\n",
      "epoch: 5 - total loss: [0.17797575]\n",
      "    actual: [0], prediction: 0.10903182755268614\n",
      "    actual: [1], prediction: 0.8273717796510367\n",
      "    actual: [0], prediction: -0.17037324196481937\n",
      "    actual: [1], prediction: 1.1537962739591758\n",
      "    actual: [1], prediction: 0.8481754931254761\n",
      "    actual: [0], prediction: 0.10594880416914437\n",
      "epoch: 6 - total loss: [0.12864461]\n",
      "    actual: [0], prediction: 0.08475904333531548\n",
      "    actual: [1], prediction: 0.859469609749935\n",
      "    actual: [0], prediction: -0.15855084020224214\n",
      "    actual: [1], prediction: 1.1438418857156731\n",
      "    actual: [1], prediction: 0.8746623946770374\n",
      "    actual: [0], prediction: 0.08148074110264472\n",
      "epoch: 7 - total loss: [0.09511037]\n",
      "    actual: [0], prediction: 0.06518459288211578\n",
      "    actual: [1], prediction: 0.8850633823431537\n",
      "    actual: [0], prediction: -0.1477190558540804\n",
      "    actual: [1], prediction: 1.1341830033853888\n",
      "    actual: [1], prediction: 0.8959860107828533\n",
      "    actual: [0], prediction: 0.06197803990142217\n",
      "epoch: 8 - total loss: [0.07194564]\n",
      "    actual: [0], prediction: 0.04958243192113773\n",
      "    actual: [1], prediction: 0.9056327614440267\n",
      "    actual: [0], prediction: -0.13768337501215527\n",
      "    actual: [1], prediction: 1.1250605910610996\n",
      "    actual: [1], prediction: 0.9132624284442169\n",
      "    actual: [0], prediction: 0.046532645837081416\n",
      "epoch: 9 - total loss: [0.05564915]\n",
      "    actual: [0], prediction: 0.03722611666966513\n",
      "    actual: [1], prediction: 0.9222340665046989\n",
      "    actual: [0], prediction: -0.12834662236261596\n",
      "    actual: [1], prediction: 1.116526024487899\n",
      "    actual: [1], prediction: 0.9273167105424409\n",
      "    actual: [0], prediction: 0.034355272969699896\n",
      "epoch: 10 - total loss: [0.04394764]\n",
      "    actual: [0], prediction: 0.027484218375759914\n",
      "    actual: [1], prediction: 0.9356694192994068\n",
      "    actual: [0], prediction: -0.11964712469387503\n",
      "    actual: [1], prediction: 1.1085678053734553\n",
      "    actual: [1], prediction: 0.9387866868342218\n",
      "    actual: [0], prediction: 0.024792915481941485\n",
      "epoch: 11 - total loss: [0.03535797]\n",
      "    actual: [0], prediction: 0.019834332385553183\n",
      "    actual: [1], prediction: 0.946566624680628\n",
      "    actual: [0], prediction: -0.11153724870006754\n",
      "    actual: [1], prediction: 1.1011550767549563\n",
      "    actual: [1], prediction: 0.948176009263518\n",
      "    actual: [0], prediction: 0.017315912033043432\n",
      "epoch: 12 - total loss: [0.028907]\n",
      "    actual: [0], prediction: 0.013852729626434745\n",
      "    actual: [1], prediction: 0.9554239432448665\n",
      "    actual: [0], prediction: -0.10397589092234266\n",
      "    actual: [1], prediction: 1.0942524239871314\n",
      "    actual: [1], prediction: 0.9558862588907013\n",
      "    actual: [0], prediction: 0.011498267782399\n",
      "epoch: 13 - total loss: [0.02395166]\n",
      "    actual: [0], prediction: 0.009198614225919208\n",
      "    actual: [1], prediction: 0.9626393189117293\n",
      "    actual: [0], prediction: -0.09692579020989642\n",
      "    actual: [1], prediction: 1.0878247838498318\n",
      "    actual: [1], prediction: 0.9622390773804066\n",
      "    actual: [0], prediction: 0.006998674002545058\n",
      "epoch: 14 - total loss: [0.02006311]\n",
      "    actual: [0], prediction: 0.005598939202036052\n",
      "    actual: [1], prediction: 0.9685315005838673\n",
      "    actual: [0], prediction: -0.09035250869077545\n",
      "    actual: [1], prediction: 1.0818389613301889\n",
      "    actual: [1], prediction: 0.9674926590701334\n",
      "    actual: [0], prediction: 0.003544193999268558\n",
      "epoch: 15 - total loss: [0.01695209]\n",
      "    actual: [0], prediction: 0.0028353551994148574\n",
      "    actual: [1], prediction: 0.9733561723362383\n",
      "    actual: [0], prediction: -0.08422399201522228\n",
      "    actual: [1], prediction: 1.0762639960116431\n",
      "    actual: [1], prediction: 0.9718545378681842\n",
      "    actual: [0], prediction: 0.0009168131382832484\n",
      "epoch: 16 - total loss: [0.01442082]\n",
      "    actual: [0], prediction: 0.000733450510626607\n",
      "    actual: [1], prediction: 0.9773186039296565\n",
      "    actual: [0], prediction: -0.07851033295953942\n",
      "    actual: [1], prediction: 1.0710711494147542\n",
      "    actual: [1], prediction: 0.9754916865567282\n",
      "    actual: [0], prediction: -0.0010574652271340829\n",
      "epoch: 17 - total loss: [0.01233174]\n",
      "    actual: [0], prediction: -0.0008459721817072746\n",
      "    actual: [1], prediction: 0.9805836929862668\n",
      "    actual: [0], prediction: -0.07318360881847627\n",
      "    actual: [1], prediction: 1.066233777045345\n",
      "    actual: [1], prediction: 0.9785385598617921\n",
      "    actual: [0], prediction: -0.0025173975573930807\n",
      "epoch: 18 - total loss: [0.01058739]\n",
      "    actual: [0], prediction: -0.00201391804591447\n",
      "    actual: [1], prediction: 0.9832839794497644\n",
      "    actual: [0], prediction: -0.06821774801198803\n",
      "    actual: [1], prediction: 1.0617271739912904\n",
      "    actual: [1], prediction: 0.9811035235627523\n",
      "    actual: [0], prediction: -0.003573544735042518\n",
      "epoch: 19 - total loss: [0.00911723]\n",
      "    actual: [0], prediction: -0.00285883578803401\n",
      "    actual: [1], prediction: 0.9855260569025094\n",
      "    actual: [0], prediction: -0.06358841060413678\n",
      "    actual: [1], prediction: 1.05752842286588\n",
      "    actual: [1], prediction: 0.9832740020092452\n",
      "    actual: [0], prediction: -0.004313918034364962\n",
      "epoch: 20 - total loss: [0.00786904]\n",
      "    actual: [0], prediction: -0.003451134427491974\n",
      "    actual: [1], prediction: 0.9873957068535818\n",
      "    actual: [0], prediction: -0.05927287747040809\n",
      "    actual: [1], prediction: 1.0536162524729626\n",
      "    actual: [1], prediction: 0.9851206027353137\n",
      "    actual: [0], prediction: -0.004808501248434842\n",
      "epoch: 21 - total loss: [0.00680327]\n",
      "    actual: [0], prediction: -0.0038468009987478735\n",
      "    actual: [1], prediction: 0.9889620124129692\n",
      "    actual: [0], prediction: -0.055249946260773564\n",
      "    actual: [1], prediction: 1.0499709087769311\n",
      "    actual: [1], prediction: 0.9867004228010665\n",
      "    actual: [0], prediction: -0.005112871449710746\n",
      "epoch: 22 - total loss: [0.0058893]\n",
      "    actual: [0], prediction: -0.004090297159768594\n",
      "    actual: [1], prediction: 0.9902806551018011\n",
      "    actual: [0], prediction: -0.05149983344172815\n",
      "    actual: [1], prediction: 1.0465740376293469\n",
      "    actual: [1], prediction: 0.9880596998997442\n",
      "    actual: [0], prediction: -0.005271097409665956\n",
      "epoch: 23 - total loss: [0.00510293]\n",
      "    actual: [0], prediction: -0.0042168779277327595\n",
      "    actual: [1], prediction: 0.991396557453535\n",
      "    actual: [0], prediction: -0.04800408206207807\n",
      "    actual: [1], prediction: 1.0434085781435742\n",
      "    actual: [1], prediction: 0.9892359385403211\n",
      "    actual: [0], prediction: -0.005318059364078864\n",
      "epoch: 24 - total loss: [0.00442464]\n",
      "    actual: [0], prediction: -0.004254447491263094\n",
      "    actual: [1], prediction: 0.992346001517791\n",
      "    actual: [0], prediction: -0.0447454749905047\n",
      "    actual: [1], prediction: 1.0404586655589982\n",
      "    actual: [1], prediction: 0.9902596156014837\n",
      "    actual: [0], prediction: -0.00528130531768712\n",
      "epoch: 25 - total loss: [0.00383851]\n",
      "    actual: [0], prediction: -0.004225044254149692\n",
      "    actual: [1], prediction: 0.9931583274383705\n",
      "    actual: [0], prediction: -0.04170795339415578\n",
      "    actual: [1], prediction: 1.037709542537111\n",
      "    actual: [1], prediction: 0.99115554878269\n",
      "    actual: [0], prediction: -0.005182536193432417\n",
      "epoch: 26 - total loss: [0.00333131]\n",
      "    actual: [0], prediction: -0.004146028954745938\n",
      "    actual: [1], prediction: 0.9938572955409697\n",
      "    actual: [0], prediction: -0.038876540225999436\n",
      "    actual: [1], prediction: 1.0351474779634815\n",
      "    actual: [1], prediction: 0.9919439948626795\n",
      "    actual: [0], prediction: -0.0050387937742580255\n",
      "epoch: 27 - total loss: [0.00289194]\n",
      "    actual: [0], prediction: -0.004031035019406416\n",
      "    actual: [1], prediction: 0.99446217876951\n",
      "    actual: [0], prediction: -0.03623726848360014\n",
      "    actual: [1], prediction: 1.0327596924550921\n",
      "    actual: [1], prediction: 0.9926415313729495\n",
      "    actual: [0], prediction: -0.0048634106724294995\n",
      "epoch: 28 - total loss: [0.00251105]\n",
      "    actual: [0], prediction: -0.0038907285379436024\n",
      "    actual: [1], prediction: 0.9949886390193968\n",
      "    actual: [0], prediction: -0.03377711399894667\n",
      "    actual: [1], prediction: 1.0305342898820642\n",
      "    actual: [1], prediction: 0.9932617646389992\n",
      "    actual: [0], prediction: -0.0046667697727126554\n",
      "epoch: 29 - total loss: [0.00218067]\n",
      "    actual: [0], prediction: -0.0037334158181701257\n",
      "    actual: [1], prediction: 0.9954494302702876\n",
      "    actual: [0], prediction: -0.03148393251909883\n",
      "    actual: [1], prediction: 1.0284601943056741\n",
      "    actual: [1], prediction: 0.9938158986070051\n",
      "    actual: [0], prediction: -0.004456911151490332\n",
      "epoch: 30 - total loss: [0.00189397]\n",
      "    actual: [0], prediction: -0.003565528921192263\n",
      "    actual: [1], prediction: 0.9958549628928723\n",
      "    actual: [0], prediction: -0.029346400840475854\n",
      "    actual: [1], prediction: 1.0265270918125804\n",
      "    actual: [1], prediction: 0.9943131920358295\n",
      "    actual: [0], prediction: -0.004240016908292486\n",
      "epoch: 31 - total loss: [0.00164511]\n",
      "    actual: [0], prediction: -0.003392013526633989\n",
      "    actual: [1], prediction: 0.9962137566721563\n",
      "    actual: [0], prediction: -0.027353961764992236\n",
      "    actual: [1], prediction: 1.0247253767906936\n",
      "    actual: [1], prediction: 0.9947613261560856\n",
      "    actual: [0], prediction: -0.004020798285770885\n",
      "epoch: 32 - total loss: [0.00142904]\n",
      "    actual: [0], prediction: -0.003216638628616708\n",
      "    actual: [1], prediction: 0.9965328046163072\n",
      "    actual: [0], prediction: -0.0254967726533629\n",
      "    actual: [1], prediction: 1.0230461022472208\n",
      "    actual: [1], prediction: 0.9951667005089379\n",
      "    actual: [0], prediction: -0.0038028045995257415\n",
      "epoch: 33 - total loss: [0.0012414]\n",
      "    actual: [0], prediction: -0.003042243679620596\n",
      "    actual: [1], prediction: 0.996817865235065\n",
      "    actual: [0], prediction: -0.02376565735923434\n",
      "    actual: [1], prediction: 1.0214809338160067\n",
      "    actual: [1], prediction: 0.995534671160774\n",
      "    actual: [0], prediction: -0.0035886696105582767\n",
      "epoch: 34 - total loss: [0.00107844]\n",
      "    actual: [0], prediction: -0.0028709356884466207\n",
      "    actual: [1], prediction: 0.9970736974585197\n",
      "    actual: [0], prediction: -0.022152061336940452\n",
      "    actual: [1], prediction: 1.0200221071408409\n",
      "    actual: [1], prediction: 0.9958697426723416\n",
      "    actual: [0], prediction: -0.0033803078583175515\n",
      "epoch: 35 - total loss: [0.00093689]\n",
      "    actual: [0], prediction: -0.002704246286654041\n",
      "    actual: [1], prediction: 0.9973042495523706\n",
      "    actual: [0], prediction: -0.020648009725304554\n",
      "    actual: [1], prediction: 1.0186623883551713\n",
      "    actual: [1], prediction: 0.9961757229433927\n",
      "    actual: [0], prediction: -0.0031790709774033796\n",
      "epoch: 36 - total loss: [0.00081394]\n",
      "    actual: [0], prediction: -0.002543256781922701\n",
      "    actual: [1], prediction: 0.9975128111306468\n",
      "    actual: [0], prediction: -0.019246068219762578\n",
      "    actual: [1], prediction: 1.0173950374076535\n",
      "    actual: [1], prediction: 0.9964558482449631\n",
      "    actual: [0], prediction: -0.0029858720226535983\n",
      "epoch: 37 - total loss: [0.00070713]\n",
      "    actual: [0], prediction: -0.002388697618122878\n",
      "    actual: [1], prediction: 0.9977021355600483\n",
      "    actual: [0], prediction: -0.01793930655497516\n",
      "    actual: [1], prediction: 1.016213774008008\n",
      "    actual: [1], prediction: 0.9967128843019345\n",
      "    actual: [0], prediction: -0.0028012842268006505\n",
      "epoch: 38 - total loss: [0.00061434]\n",
      "    actual: [0], prediction: -0.0022410273814405194\n",
      "    actual: [1], prediction: 0.9978745386023716\n",
      "    actual: [0], prediction: -0.016721264429884933\n",
      "    actual: [1], prediction: 1.0151127459893812\n",
      "    actual: [1], prediction: 0.9969492081270097\n",
      "    actual: [0], prediction: -0.00262561933297829\n",
      "epoch: 39 - total loss: [0.00053374]\n",
      "    actual: [0], prediction: -0.0021004954663826313\n",
      "    actual: [1], prediction: 0.9980319779815437\n",
      "    actual: [0], prediction: -0.015585919716753811\n",
      "    actual: [1], prediction: 1.0140864999024037\n",
      "    actual: [1], prediction: 0.9971668743764297\n",
      "    actual: [0], prediction: -0.002458989617708818\n",
      "epoch: 40 - total loss: [0.00046371]\n",
      "    actual: [0], prediction: -0.0019671916941670555\n",
      "    actual: [1], prediction: 0.9981761176323313\n",
      "    actual: [0], prediction: -0.014527658805007315\n",
      "    actual: [1], prediction: 1.0131299536728062\n",
      "    actual: [1], prediction: 0.9973676692518045\n",
      "    actual: [0], prediction: -0.0023013568978077405\n",
      "epoch: 41 - total loss: [0.00040287]\n",
      "    actual: [0], prediction: -0.0018410855182461935\n",
      "    actual: [1], prediction: 0.998308379643049\n",
      "    actual: [0], prediction: -0.013541248939667164\n",
      "    actual: [1], prediction: 1.0122383711691714\n",
      "    actual: [1], prediction: 0.9975531543745717\n",
      "    actual: [0], prediction: -0.0021525711562265792\n",
      "epoch: 42 - total loss: [0.00035001]\n",
      "    actual: [0], prediction: -0.0017220569249812648\n",
      "    actual: [1], prediction: 0.9984299863077781\n",
      "    actual: [0], prediction: -0.012621812422731783\n",
      "    actual: [1], prediction: 1.0114073385404647\n",
      "    actual: [1], prediction: 0.9977247025804028\n",
      "    actual: [0], prediction: -0.00201240089462287\n",
      "epoch: 43 - total loss: [0.00030409]\n",
      "    actual: [0], prediction: -0.0016099207156982966\n",
      "    actual: [1], prediction: 0.9985419942253542\n",
      "    actual: [0], prediction: -0.011764802554048657\n",
      "    actual: [1], prediction: 1.0106327421946428\n",
      "    actual: [1], prediction: 0.9978835271967597\n",
      "    actual: [0], prediction: -0.0018805568982937192\n",
      "epoch: 44 - total loss: [0.0002642]\n",
      "    actual: [0], prediction: -0.0015044455186349753\n",
      "    actual: [1], prediction: 0.9986453219991005\n",
      "    actual: [0], prediction: -0.010965981196001222\n",
      "    actual: [1], prediction: 1.0099107483000638\n",
      "    actual: [1], prediction: 0.9980307060588679\n",
      "    actual: [0], prediction: -0.0017567107611174554\n",
      "epoch: 45 - total loss: [0.00022954]\n",
      "    actual: [0], prediction: -0.0014053686088939636\n",
      "    actual: [1], prediction: 0.9987407727840956\n",
      "    actual: [0], prediction: -0.010221397853702682\n",
      "    actual: [1], prediction: 1.0092377837008246\n",
      "    actual: [1], prediction: 0.9981672012724818\n",
      "    actual: [0], prediction: -0.001640509247567562\n",
      "epoch: 46 - total loss: [0.00019942]\n",
      "    actual: [0], prediction: -0.0013124073980540496\n",
      "    actual: [1], prediction: 0.9988290526825476\n",
      "    actual: [0], prediction: -0.009527370169355657\n",
      "    actual: [1], prediction: 1.0086105181456313\n",
      "    actual: [1], prediction: 0.9982938755338475\n",
      "    actual: [0], prediction: -0.001531585352273446\n",
      "epoch: 47 - total loss: [0.00017326]\n",
      "    actual: [0], prediction: -0.0012252682818187574\n",
      "    actual: [1], prediction: 0.9989107857904872\n",
      "    actual: [0], prediction: -0.008880465736007473\n",
      "    actual: [1], prediction: 1.0080258477374944\n",
      "    actual: [1], prediction: 0.9984115056584917\n",
      "    actual: [0], prediction: -0.001429566744251023\n",
      "epoch: 48 - total loss: [0.00015053]\n",
      "    actual: [0], prediction: -0.0011436533954008185\n",
      "    actual: [1], prediction: 0.9989865265407586\n",
      "    actual: [0], prediction: -0.008277485142116006\n",
      "    actual: [1], prediction: 1.007480879518538\n",
      "    actual: [1], prediction: 0.998520793843111\n",
      "    actual: [0], prediction: -0.0013340821442035964\n",
      "epoch: 49 - total loss: [0.00013078]\n"
     ]
    }
   ],
   "source": [
    "# Streetlight configuration\n",
    "xs = np.array([[1, 0, 1],\n",
    "               [0, 1, 1],\n",
    "               [0, 0, 1],\n",
    "               [1, 1, 1],\n",
    "               [0, 1, 1],\n",
    "               [1, 0, 1]])\n",
    "\n",
    "# Walk versus stop\n",
    "ys = np.array([[0],\n",
    "               [1],\n",
    "               [0],\n",
    "               [1],\n",
    "               [1],\n",
    "               [0]])\n",
    "\n",
    "epochs = 50\n",
    "lr = 0.1\n",
    "\n",
    "# Neural network weights (one layer)\n",
    "w = np.array([0.5, 0.48, -0.7])\n",
    "\n",
    "# Loop over epochs\n",
    "for i in range(epochs):\n",
    "    \n",
    "    l_total = 0.0\n",
    "    \n",
    "    # Loop over dataset\n",
    "    for j in range(len(xs)):\n",
    "        \n",
    "        # Grab a new data entry\n",
    "        x_i = xs[j]\n",
    "        y_i = ys[j]\n",
    "\n",
    "        y_hat = x_i.dot(w)\n",
    "        l = (y_hat - y_i) ** 2.0\n",
    "        \n",
    "        # Accumulate loss\n",
    "        l_total += l\n",
    "        \n",
    "        dl_dw = (y_hat - y_i) * x_i\n",
    "        \n",
    "        # Perform a parameter update after each example: this is known \n",
    "        # as stochastic gradient descent (SGD)\n",
    "        w -= lr * dl_dw\n",
    "        print('    actual: {}, prediction: {}'.format(y_i, y_hat))\n",
    "\n",
    "    print('epoch: {} - total loss: {}'.format(i, l_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full-fledged 2-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: 0.6342311598444467\n",
      "total loss: 0.35838407676317513\n",
      "total loss: 0.0830183113303298\n",
      "total loss: 0.006467054957103705\n",
      "total loss: 0.0003292669000750734\n",
      "total loss: 1.5055622665134859e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntotal loss: 0.6342311598444467\\ntotal loss: 0.35838407676317513\\ntotal loss: 0.0830183113303298\\ntotal loss: 0.006467054957103705\\ntotal loss: 0.0003292669000750734\\ntotal loss: 1.5055622665134859e-05\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return 2.0 * np.random.random(shape) - 1.0\n",
    "\n",
    "def affine(x, w):\n",
    "    '''\n",
    "    Inputs:\n",
    "    - x: layer input\n",
    "    - w: layer weights\n",
    "    \n",
    "    Returns:\n",
    "    - o: layer output with the same shape as x\n",
    "    '''\n",
    "    o = x.dot(w)\n",
    "    return o\n",
    "\n",
    "def affine_backwards(dl_do, x, w):\n",
    "    '''\n",
    "    Inputs:\n",
    "    - dl_do: derivative of the network loss w.r.t. this layer's output o\n",
    "    - x: original input to this layer \n",
    "    - w: original weights associated with this layer \n",
    "    \n",
    "    Returns:\n",
    "    - [do_dx, do_dw]: tuple of two items:\n",
    "        - do_dx: partial derivative of this layer's output w.r.t. x\n",
    "        - do_dw: partial derivative of this layer's output w.r.t. w\n",
    "    '''\n",
    "    do_dx = dl_do.dot(w.T)\n",
    "    assert(do_dx.shape == x.shape)\n",
    "    \n",
    "    do_dw = x.T.dot(dl_do)\n",
    "    assert(do_dw.shape == w.shape)\n",
    "    \n",
    "    return [do_dx, do_dw]\n",
    "\n",
    "def relu(x):\n",
    "    '''A ReLU activation function, which sets all negative numbers to zero\n",
    "    \n",
    "    Inputs:\n",
    "    - x: layer input\n",
    "    \n",
    "    Returns:\n",
    "    - o: layer output with the same shape as x\n",
    "    '''\n",
    "    o = (x > 0.0) * x\n",
    "    return o\n",
    "\n",
    "def relu_backwards(dl_do, x):\n",
    "    '''\n",
    "    Inputs:\n",
    "    - dl_do:\n",
    "    - x: original input to this layer \n",
    "    \n",
    "    Returns:\n",
    "    - do_dx: partial derivative of this layer's output w.r.t. its input x\n",
    "    '''\n",
    "    do_dx = x > 0.0\n",
    "    return dl_do * do_dx\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    '''\n",
    "    Computes the MSE between the actual and predicted value(s) of `y`\n",
    "    '''\n",
    "    return np.sum((y_hat - y) ** 2.0)\n",
    "\n",
    "def reduce_sum(x):\n",
    "    return np.sum(x)\n",
    "\n",
    "def reduce_sum_backwards(o):\n",
    "    return np.ones_like(o)\n",
    "\n",
    "xs = np.array([\n",
    "    [1.0, 0.0, 1.0],\n",
    "    [0.0, 1.0, 1.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [1.0, 1.0, 1.0]\n",
    "])\n",
    "\n",
    "ys = np.array([\n",
    "    [1.0, 1.0, 0.0, 0.0]\n",
    "]).T\n",
    "\n",
    "# Build our model\n",
    "hidden_size = 4\n",
    "w0 = init_weights((3, hidden_size)) # Input -> layer 1\n",
    "w1 = init_weights((hidden_size, 1)) # Layer 1 -> layer 2\n",
    "\n",
    "# Train our model\n",
    "debug = False\n",
    "epochs = 60\n",
    "lr = 0.2\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    l_total = 0.0\n",
    "    \n",
    "    for j in range(len(xs)):\n",
    "        \n",
    "        # Rename some variables for clarity\n",
    "        x = xs[j:j + 1]\n",
    "        y = ys[j:j + 1]\n",
    "        \n",
    "        # Forward pass\n",
    "        layer_0 = x\n",
    "        layer_1 = relu(affine(layer_0, w0))\n",
    "        layer_2 = affine(layer_1, w1)\n",
    "        \n",
    "        y_hat = layer_2\n",
    "        \n",
    "        if debug:\n",
    "            print('-' * 20)\n",
    "            print('layer_0 (shape): {}'.format(layer_0.shape))\n",
    "            print('layer_1 (shape): {}'.format(layer_1.shape))\n",
    "            print('layer_2 (shape): {}'.format(layer_2.shape))\n",
    "            print('network output: {}'.format(layer_2))\n",
    "        \n",
    "         \n",
    "        \n",
    "        # The loss is a single, floating-point number\n",
    "        l = np.sum((y_hat - y) ** 2.0)\n",
    "        l_total += l\n",
    "        \n",
    "        layer_2_delta = y - y_hat\n",
    "        \n",
    "        dout = y - y_hat\n",
    "        dout = affine_backwards()\n",
    "        #dlayer2_inputs = \n",
    "        \n",
    "        layer_1_delta = relu_backwards(layer_2_delta.dot(w1.T), layer_1)\n",
    "        \n",
    "        # Calculate derivatives\n",
    "        dl_dw1 = layer_1.T.dot(layer_2_delta)\n",
    "        dl_dw0 = layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "        # Update weights\n",
    "        w1 += lr * dl_dw1\n",
    "        w0 += lr * dl_dw0\n",
    "        \n",
    "        #print('    actual: {}, prediction: {}'.format(y.flatten(), y_hat.flatten()))\n",
    "    \n",
    "    if (i % 10 == 9):\n",
    "        print('total loss: {}'.format(l_total))\n",
    "        \n",
    "        \n",
    "'''\n",
    "total loss: 0.6342311598444467\n",
    "total loss: 0.35838407676317513\n",
    "total loss: 0.0830183113303298\n",
    "total loss: 0.006467054957103705\n",
    "total loss: 0.0003292669000750734\n",
    "total loss: 1.5055622665134859e-05\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
